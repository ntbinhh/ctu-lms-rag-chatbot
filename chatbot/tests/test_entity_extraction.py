"""
Entity Extraction Performance Tests
Tests specifically for entity recognition accuracy
"""

import asyncio
import json
import re
from typing import Dict, List, Tuple
from pathlib import Path

class EntityExtractionTester:
    """Dedicated Entity Extraction Testing"""
    
    def __init__(self):
        self.entity_test_cases = []
        
    def load_entity_test_data(self):
        """Load test cases with specific entity annotations"""
        self.entity_test_cases = [
            # NÄƒm entity tests
            {
                "text": "há»c phÃ­ nÄƒm 2025 lÃ  bao nhiÃªu",
                "entities": [{"entity": "nam", "value": "2025", "start": 12, "end": 16}]
            },
            {
                "text": "tuyá»ƒn sinh nÄƒm há»c 2024-2025",
                "entities": [{"entity": "nam", "value": "2024-2025", "start": 19, "end": 28}]
            },
            {
                "text": "chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o tá»« nÄƒm 2023",
                "entities": [{"entity": "nam", "value": "2023", "start": 28, "end": 32}]
            },
            
            # NgÃ nh entity tests
            {
                "text": "chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o cÃ´ng nghá»‡ thÃ´ng tin",
                "entities": [{"entity": "nganh", "value": "cÃ´ng nghá»‡ thÃ´ng tin", "start": 22, "end": 41}]
            },
            {
                "text": "tÃ´i muá»‘n há»c ngÃ nh káº¿ toÃ¡n",
                "entities": [{"entity": "nganh", "value": "káº¿ toÃ¡n", "start": 19, "end": 26}]
            },
            {
                "text": "Ä‘iá»u kiá»‡n tuyá»ƒn sinh ngÃ nh quáº£n trá»‹ kinh doanh",
                "entities": [{"entity": "nganh", "value": "quáº£n trá»‹ kinh doanh", "start": 27, "end": 46}]
            },
            
            # Há»c ká»³ entity tests  
            {
                "text": "lá»‹ch thi há»c ká»³ 1 nÄƒm 2025",
                "entities": [
                    {"entity": "hoc_ky", "value": "1", "start": 15, "end": 16},
                    {"entity": "nam", "value": "2025", "start": 22, "end": 26}
                ]
            },
            {
                "text": "Ä‘Äƒng kÃ½ mÃ´n há»c semester 2",
                "entities": [{"entity": "hoc_ky", "value": "2", "start": 24, "end": 25}]
            },
            
            # CÆ¡ sá»Ÿ entity tests
            {
                "text": "há»c phÃ­ táº¡i cÆ¡ sá»Ÿ Cáº§n ThÆ¡",
                "entities": [{"entity": "co_so", "value": "Cáº§n ThÆ¡", "start": 18, "end": 25}]
            },
            {
                "text": "tuyá»ƒn sinh cÆ¡ sá»Ÿ An Giang",
                "entities": [{"entity": "co_so", "value": "An Giang", "start": 17, "end": 25}]
            },
            
            # Loáº¡i Ä‘Ã o táº¡o entity tests
            {
                "text": "há»c phÃ­ Ä‘Ã o táº¡o tá»« xa",
                "entities": [{"entity": "loai_dao_tao", "value": "tá»« xa", "start": 16, "end": 21}]
            },
            {
                "text": "chÆ°Æ¡ng trÃ¬nh chÃ­nh quy",
                "entities": [{"entity": "loai_dao_tao", "value": "chÃ­nh quy", "start": 13, "end": 23}]
            },
            
            # Mixed entity tests
            {
                "text": "há»c phÃ­ ngÃ nh cÃ´ng nghá»‡ thÃ´ng tin táº¡i cÆ¡ sá»Ÿ Cáº§n ThÆ¡ nÄƒm 2025",
                "entities": [
                    {"entity": "nganh", "value": "cÃ´ng nghá»‡ thÃ´ng tin", "start": 14, "end": 33},
                    {"entity": "co_so", "value": "Cáº§n ThÆ¡", "start": 44, "end": 51},
                    {"entity": "nam", "value": "2025", "start": 56, "end": 60}
                ]
            },
            
            # No entity tests
            {
                "text": "xin chÃ o tÃ´i cáº§n há»— trá»£",
                "entities": []
            },
            {
                "text": "cáº£m Æ¡n báº¡n Ä‘Ã£ giÃºp Ä‘á»¡",
                "entities": []
            }
        ]
        
    def manual_entity_extraction(self, text: str) -> List[Dict]:
        """Manual rule-based entity extraction for comparison"""
        entities = []
        text_lower = text.lower()
        
        # Year patterns
        year_patterns = [
            r'\b(20\d{2})\b',  # 2025, 2024, etc.
            r'\b(20\d{2}-20\d{2})\b',  # 2024-2025
        ]
        
        for pattern in year_patterns:
            for match in re.finditer(pattern, text):
                entities.append({
                    "entity": "nam",
                    "value": match.group(1),
                    "start": match.start(),
                    "end": match.end()
                })
        
        # NgÃ nh patterns
        nganh_keywords = [
            "cÃ´ng nghá»‡ thÃ´ng tin", "káº¿ toÃ¡n", "quáº£n trá»‹ kinh doanh", 
            "kinh táº¿", "luáº­t", "nÃ´ng nghiá»‡p", "thá»§y sáº£n", "y há»c"
        ]
        
        for keyword in nganh_keywords:
            start = text_lower.find(keyword)
            if start != -1:
                entities.append({
                    "entity": "nganh",
                    "value": keyword,
                    "start": start,
                    "end": start + len(keyword)
                })
        
        # Há»c ká»³ patterns
        hoc_ky_patterns = [
            r'há»c ká»³ (\d)',
            r'semester (\d)',
            r'ká»³ (\d)'
        ]
        
        for pattern in hoc_ky_patterns:
            for match in re.finditer(pattern, text_lower):
                entities.append({
                    "entity": "hoc_ky", 
                    "value": match.group(1),
                    "start": match.start(1),
                    "end": match.end(1)
                })
        
        # CÆ¡ sá»Ÿ patterns
        co_so_keywords = ["Cáº§n ThÆ¡", "An Giang", "Háº­u Giang", "SÃ³c TrÄƒng", "Báº¡c LiÃªu"]
        
        for keyword in co_so_keywords:
            start = text.find(keyword)
            if start != -1:
                entities.append({
                    "entity": "co_so",
                    "value": keyword,
                    "start": start,
                    "end": start + len(keyword)
                })
                
        # Loáº¡i Ä‘Ã o táº¡o patterns
        loai_dao_tao_keywords = ["tá»« xa", "chÃ­nh quy", "liÃªn thÃ´ng"]
        
        for keyword in loai_dao_tao_keywords:
            start = text_lower.find(keyword)
            if start != -1:
                entities.append({
                    "entity": "loai_dao_tao",
                    "value": keyword,
                    "start": start,
                    "end": start + len(keyword)
                })
        
        return entities
        
    async def test_rasa_entity_extraction(self):
        """Test entity extraction using RASA"""
        try:
            from rasa.core.agent import Agent
            import os
            
            # Load latest model
            model_dir = Path("models")
            if not model_dir.exists():
                return None
                
            model_files = list(model_dir.glob("*.tar.gz"))
            if not model_files:
                return None
                
            latest_model = max(model_files, key=os.path.getctime)
            agent = Agent.load(str(latest_model))
            
            results = {
                "total_cases": len(self.entity_test_cases),
                "entity_results": [],
                "by_entity_type": {},
                "overall_metrics": {}
            }
            
            all_true_entities = []
            all_pred_entities = []
            
            for test_case in self.entity_test_cases:
                rasa_result = await agent.parse_message(test_case["text"])
                
                true_entities = test_case["entities"]
                pred_entities = rasa_result["entities"]
                
                # Convert to comparable format
                true_set = set((e["entity"], e["value"]) for e in true_entities)
                pred_set = set((e["entity"], e["value"]) for e in pred_entities)
                
                all_true_entities.extend(true_set)
                all_pred_entities.extend(pred_set)
                
                case_result = {
                    "text": test_case["text"],
                    "true_entities": true_entities,
                    "pred_entities": pred_entities,
                    "true_count": len(true_entities),
                    "pred_count": len(pred_entities),
                    "correct_count": len(true_set & pred_set),
                    "precision": len(true_set & pred_set) / len(pred_set) if pred_set else 1.0,
                    "recall": len(true_set & pred_set) / len(true_set) if true_set else 1.0
                }
                
                results["entity_results"].append(case_result)
            
            # Calculate overall metrics
            all_true_set = set(all_true_entities)
            all_pred_set = set(all_pred_entities)
            
            overall_precision = len(all_true_set & all_pred_set) / len(all_pred_set) if all_pred_set else 1.0
            overall_recall = len(all_true_set & all_pred_set) / len(all_true_set) if all_true_set else 1.0
            overall_f1 = 2 * overall_precision * overall_recall / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0.0
            
            results["overall_metrics"] = {
                "precision": overall_precision,
                "recall": overall_recall,
                "f1": overall_f1,
                "total_true_entities": len(all_true_set),
                "total_pred_entities": len(all_pred_set),
                "total_correct": len(all_true_set & all_pred_set)
            }
            
            # Calculate by entity type
            entity_types = set(e[0] for e in all_true_entities) | set(e[0] for e in all_pred_entities)
            
            for entity_type in entity_types:
                type_true = set(e for e in all_true_entities if e[0] == entity_type)
                type_pred = set(e for e in all_pred_entities if e[0] == entity_type)
                
                type_precision = len(type_true & type_pred) / len(type_pred) if type_pred else 1.0
                type_recall = len(type_true & type_pred) / len(type_true) if type_true else 1.0
                type_f1 = 2 * type_precision * type_recall / (type_precision + type_recall) if (type_precision + type_recall) > 0 else 0.0
                
                results["by_entity_type"][entity_type] = {
                    "precision": type_precision,
                    "recall": type_recall,
                    "f1": type_f1,
                    "true_count": len(type_true),
                    "pred_count": len(type_pred),
                    "correct_count": len(type_true & type_pred)
                }
            
            return results
            
        except ImportError:
            print("âš ï¸ RASA not available for entity testing")
            return None
        except Exception as e:
            print(f"âŒ RASA entity test error: {e}")
            return None
            
    def test_manual_entity_extraction(self):
        """Test manual entity extraction"""
        results = {
            "total_cases": len(self.entity_test_cases),
            "entity_results": [],
            "by_entity_type": {},
            "overall_metrics": {}
        }
        
        all_true_entities = []
        all_pred_entities = []
        
        for test_case in self.entity_test_cases:
            true_entities = test_case["entities"]
            pred_entities = self.manual_entity_extraction(test_case["text"])
            
            # Convert to comparable format
            true_set = set((e["entity"], e["value"]) for e in true_entities)
            pred_set = set((e["entity"], e["value"]) for e in pred_entities)
            
            all_true_entities.extend(true_set)
            all_pred_entities.extend(pred_set)
            
            case_result = {
                "text": test_case["text"],
                "true_entities": true_entities,
                "pred_entities": pred_entities,
                "true_count": len(true_entities),
                "pred_count": len(pred_entities),
                "correct_count": len(true_set & pred_set),
                "precision": len(true_set & pred_set) / len(pred_set) if pred_set else 1.0,
                "recall": len(true_set & pred_set) / len(true_set) if true_set else 1.0
            }
            
            results["entity_results"].append(case_result)
        
        # Calculate overall metrics (same as RASA method)
        all_true_set = set(all_true_entities)
        all_pred_set = set(all_pred_entities)
        
        overall_precision = len(all_true_set & all_pred_set) / len(all_pred_set) if all_pred_set else 1.0
        overall_recall = len(all_true_set & all_pred_set) / len(all_true_set) if all_true_set else 1.0
        overall_f1 = 2 * overall_precision * overall_recall / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0.0
        
        results["overall_metrics"] = {
            "precision": overall_precision,
            "recall": overall_recall,
            "f1": overall_f1,
            "total_true_entities": len(all_true_set),
            "total_pred_entities": len(all_pred_set),
            "total_correct": len(all_true_set & all_pred_set)
        }
        
        # Calculate by entity type
        entity_types = set(e[0] for e in all_true_entities) | set(e[0] for e in all_pred_entities)
        
        for entity_type in entity_types:
            type_true = set(e for e in all_true_entities if e[0] == entity_type)
            type_pred = set(e for e in all_pred_entities if e[0] == entity_type)
            
            type_precision = len(type_true & type_pred) / len(type_pred) if type_pred else 1.0
            type_recall = len(type_true & type_pred) / len(type_true) if type_true else 1.0
            type_f1 = 2 * type_precision * type_recall / (type_precision + type_recall) if (type_precision + type_recall) > 0 else 0.0
            
            results["by_entity_type"][entity_type] = {
                "precision": type_precision,
                "recall": type_recall,
                "f1": type_f1,
                "true_count": len(type_true),
                "pred_count": len(type_pred),
                "correct_count": len(type_true & type_pred)
            }
        
        return results
        
    async def run_entity_tests(self):
        """Run all entity extraction tests"""
        print("ğŸ·ï¸ Starting Entity Extraction Tests")
        print("="*50)
        
        self.load_entity_test_data()
        print(f"ğŸ“‹ Loaded {len(self.entity_test_cases)} entity test cases")
        
        # Test RASA entity extraction
        print("\nğŸ¤– Testing RASA Entity Extraction...")
        rasa_results = await self.test_rasa_entity_extraction()
        
        # Test manual entity extraction  
        print("\nğŸ“ Testing Manual Entity Extraction...")
        manual_results = self.test_manual_entity_extraction()
        
        # Generate report
        report = {
            "timestamp": asyncio.get_event_loop().time(),
            "test_summary": {
                "total_test_cases": len(self.entity_test_cases),
                "entity_types_tested": list(set(e["entity"] for case in self.entity_test_cases for e in case["entities"]))
            },
            "rasa_entity_results": rasa_results,
            "manual_entity_results": manual_results
        }
        
        # Print results
        print("\n" + "="*50)
        print("ğŸ·ï¸ ENTITY EXTRACTION RESULTS")
        print("="*50)
        
        if rasa_results:
            metrics = rasa_results["overall_metrics"]
            print(f"ğŸ¤– RASA Entity Extraction:")
            print(f"   Precision: {metrics['precision']:.3f}")
            print(f"   Recall:    {metrics['recall']:.3f}")
            print(f"   F1 Score:  {metrics['f1']:.3f}")
            
            # Performance assessment
            f1_threshold = 0.92
            status = "âœ… PASS" if metrics['f1'] >= f1_threshold else "âŒ FAIL"
            print(f"   Status:    {status} (Target: F1 â‰¥ {f1_threshold})")
            
            print(f"\n   By Entity Type:")
            for entity_type, type_metrics in rasa_results["by_entity_type"].items():
                print(f"     {entity_type}: F1={type_metrics['f1']:.3f}, P={type_metrics['precision']:.3f}, R={type_metrics['recall']:.3f}")
        
        if manual_results:
            metrics = manual_results["overall_metrics"] 
            print(f"\nğŸ“ Manual Entity Extraction:")
            print(f"   Precision: {metrics['precision']:.3f}")
            print(f"   Recall:    {metrics['recall']:.3f}")
            print(f"   F1 Score:  {metrics['f1']:.3f}")
        
        # Save results
        print(f"\nğŸ’¾ Saving entity test results...")
        with open("entity_test_results.json", "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print("âœ… Results saved to entity_test_results.json")
        
        return report


async def main():
    """Main entity test runner"""
    tester = EntityExtractionTester()
    
    try:
        await tester.run_entity_tests()
        print("\nâœ… Entity extraction tests completed!")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Tests interrupted by user")
    except Exception as e:
        print(f"\nâŒ Tests failed with error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
