#!/usr/bin/env python3
"""
Script kiá»ƒm tra vÃ  quáº£n lÃ½ models Ä‘Ã£ download
"""

import os
import sys
import shutil
from pathlib import Path
from sentence_transformers import SentenceTransformer

def print_status(message, status="INFO"):
    """In thÃ´ng bÃ¡o vá»›i icon"""
    status_icon = {
        "INFO": "â„¹ï¸",
        "SUCCESS": "âœ…", 
        "ERROR": "âŒ",
        "WARNING": "âš ï¸",
        "FOUND": "ğŸ”"
    }
    print(f"{status_icon.get(status, 'â„¹ï¸')} {message}")

def check_huggingface_cache():
    """Kiá»ƒm tra cache HuggingFace"""
    print_status("Kiá»ƒm tra HuggingFace cache...")
    
    # CÃ¡c Ä‘Æ°á»ng dáº«n cache phá»• biáº¿n
    cache_paths = [
        Path.home() / ".cache" / "huggingface",
        Path.home() / ".cache" / "torch" / "sentence_transformers",
        Path(os.environ.get("HF_HOME", "")) if os.environ.get("HF_HOME") else None
    ]
    
    cache_paths = [p for p in cache_paths if p and p.exists()]
    
    if not cache_paths:
        print_status("KhÃ´ng tÃ¬m tháº¥y cache HuggingFace", "ERROR")
        return None
    
    for cache_path in cache_paths:
        print_status(f"TÃ¬m tháº¥y cache táº¡i: {cache_path}", "FOUND")
        
        # List cÃ¡c models trong cache
        if cache_path.exists():
            for item in cache_path.rglob("*"):
                if "vietnamese-sbert" in str(item) or "all-MiniLM" in str(item) or "gte-multilingual" in str(item):
                    print_status(f"   Model: {item.name}", "INFO")
    
    return cache_paths[0]

def test_models():
    """Test xem cÃ¡c models cÃ³ load Ä‘Æ°á»£c khÃ´ng"""
    print_status("Testing cÃ¡c models...")
    
    models_to_test = [
        "keepitreal/vietnamese-sbert",
        "sentence-transformers/all-MiniLM-L6-v2", 
        "Alibaba-NLP/gte-multilingual-base"
    ]
    
    working_models = []
    
    for model_name in models_to_test:
        try:
            print_status(f"Loading {model_name}...", "INFO")
            model = SentenceTransformer(model_name)
            
            # Test encoding
            test_text = "Xin chÃ o, Ä‘Ã¢y lÃ  cÃ¢u test"
            embedding = model.encode(test_text)
            
            print_status(f"âœ… {model_name} hoáº¡t Ä‘á»™ng OK (dim: {len(embedding)})", "SUCCESS")
            working_models.append(model_name)
            
        except Exception as e:
            print_status(f"âŒ {model_name} lá»—i: {str(e)}", "ERROR")
    
    return working_models

def show_model_locations():
    """Hiá»ƒn thá»‹ vá»‹ trÃ­ cÃ¡c models"""
    print_status("Vá»‹ trÃ­ lÆ°u trá»¯ models:")
    
    try:
        from sentence_transformers import SentenceTransformer
        
        # Láº¥y cache folder máº·c Ä‘á»‹nh
        temp_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        cache_folder = temp_model._cache_folder
        print_status(f"Cache folder: {cache_folder}", "INFO")
        
        # List ná»™i dung cache folder
        if Path(cache_folder).exists():
            for item in Path(cache_folder).iterdir():
                if item.is_dir():
                    print_status(f"   ğŸ“ {item.name}", "FOUND")
                    
                    # Kiá»ƒm tra size
                    size = sum(f.stat().st_size for f in item.rglob('*') if f.is_file())
                    size_mb = size / (1024 * 1024)
                    print_status(f"      Size: {size_mb:.1f} MB", "INFO")
        
    except Exception as e:
        print_status(f"Lá»—i kiá»ƒm tra cache: {e}", "ERROR")

def copy_models_to_local():
    """Copy models tá»« cache vá» thÆ° má»¥c local"""
    print_status("Copy models vá» thÆ° má»¥c local...")
    
    local_models_dir = Path("models")
    local_models_dir.mkdir(exist_ok=True)
    
    try:
        # Láº¥y Ä‘Æ°á»ng dáº«n cache
        temp_model = SentenceTransformer("keepitreal/vietnamese-sbert")
        cache_folder = Path(temp_model._cache_folder)
        
        model_folders = {
            "vietnamese-sbert": None,
            "all-MiniLM-L6-v2": None,
            "gte-multilingual-base": None
        }
        
        # TÃ¬m cÃ¡c thÆ° má»¥c model
        for item in cache_folder.iterdir():
            if item.is_dir():
                item_name = item.name.lower()
                if "vietnamese-sbert" in item_name:
                    model_folders["vietnamese-sbert"] = item
                elif "all-minilm-l6-v2" in item_name:
                    model_folders["all-MiniLM-L6-v2"] = item
                elif "gte-multilingual-base" in item_name:
                    model_folders["gte-multilingual-base"] = item
        
        # Copy tá»«ng model
        for model_name, source_path in model_folders.items():
            if source_path and source_path.exists():
                dest_path = local_models_dir / model_name
                
                if dest_path.exists():
                    print_status(f"{model_name} Ä‘Ã£ tá»“n táº¡i trong local", "WARNING")
                else:
                    print_status(f"Copying {model_name}...", "INFO")
                    shutil.copytree(source_path, dest_path)
                    print_status(f"âœ… Copied {model_name}", "SUCCESS")
            else:
                print_status(f"âŒ KhÃ´ng tÃ¬m tháº¥y {model_name} trong cache", "ERROR")
    
    except Exception as e:
        print_status(f"Lá»—i copy models: {e}", "ERROR")

def main():
    """Main function"""
    print("ğŸ” KIá»‚M TRA VÃ€ QUáº¢N LÃ MODELS")
    print("=" * 50)
    
    # 1. Kiá»ƒm tra cache
    cache_path = check_huggingface_cache()
    print()
    
    # 2. Test models
    working_models = test_models()
    print()
    
    # 3. Hiá»ƒn thá»‹ vá»‹ trÃ­ models
    show_model_locations()
    print()
    
    # 4. Hiá»ƒn thá»‹ thÃ´ng tin current model
    print_status("ThÃ´ng tin model hiá»‡n táº¡i trong .env:")
    try:
        with open(".env", "r", encoding="utf-8") as f:
            lines = f.readlines()
            for line in lines:
                if "EMBEDDINGS_MODEL" in line:
                    print_status(f"   {line.strip()}", "INFO")
    except FileNotFoundError:
        print_status("KhÃ´ng tÃ¬m tháº¥y file .env", "WARNING")
    
    print()
    
    # 5. TÃ¹y chá»n copy vá» local
    print_status("ğŸ’¡ CÃ¡c options:")
    print("   1. Models Ä‘Ã£ Ä‘Æ°á»£c cache vÃ  sáºµn sÃ ng sá»­ dá»¥ng")
    print("   2. Náº¿u muá»‘n copy vá» thÆ° má»¥c local, gá»i copy_models_to_local()")
    print("   3. Models sáº½ load nhanh tá»« cache trong láº§n sá»­ dá»¥ng tiáº¿p theo")
    
    if len(working_models) > 0:
        print_status(f"ğŸ‰ {len(working_models)}/{len(['keepitreal/vietnamese-sbert', 'sentence-transformers/all-MiniLM-L6-v2', 'Alibaba-NLP/gte-multilingual-base'])} models sáºµn sÃ ng!", "SUCCESS")
    else:
        print_status("âŒ ChÆ°a cÃ³ model nÃ o hoáº¡t Ä‘á»™ng", "ERROR")

if __name__ == "__main__":
    main()
